## **G1 里的 Region 是不是统一大小？能不能运行时改？**

结论先说：

- 同一台 JVM 运行期间：**所有普通 Region 的大小是相同的固定值**（power of 2，介于 1MB ~ 32MB 之间）。
- 这个大小在 JVM 启动时根据堆大小自动选定，或者你用 -XX:G1HeapRegionSize 手动指定。
- 一旦确定之后，这个值**不会在运行时动态改变**。也就是说，G1 不会“热更新 Region 大小”。

为什么要这么做？

因为 G1 的整个算法是围绕“很多同尺寸的小 Region”来做的：

- 年轻代、老年代都不再是连续的大区，而是由一堆离散 Region 组成（逻辑分代）。
- 回收时可以挑出一批“回收收益高”的 Region 做局部回收（Garbage-First）。
- 记忆集 / Remembered Set（记录谁引用了谁）和各种数据结构都假设 Region 是等大小的块，这样寻址、索引、统计成本都能做到 O(1)。

如果 Region 还能在 runtime 改大小，那这些结构的代价会直接炸掉（比如 RSet 的粒度就没法简单按Region映射了）。

所以你可以把它理解成：

> G1 在启动时把整个堆切成均匀的瓷砖，后面 GC 全程都在玩这批同规格瓷砖；规格一旦选了就锁死。





## **那如果对象比一个 Region 还大呢？比如 Region=1MB，但来一个 2MB 的对象？**

这就是所谓的 **Humongous Object**（大对象）路径。

**2.1 什么算 Humongous？**

G1 认为一个对象是 Humongous（巨型）当它的大小 ≥ 1个Region大小的 50%。

举个具体的数：

- 如果 Region = 1MB
- 那超过 512KB（也就是 ≥ 0.5 * RegionSize）的对象就按 Humongous 对象处理。

注意：你的 2MB 对象肯定是 Humongous。





**2.2 Humongous 对象是怎么放的？**

G1 会为 Humongous 对象**直接分配一串连续的 Region**（不是一个，是一串）。

- 你的例子：对象大小 = 2MB
- Region 大小 = 1MB
- G1 会找 2 个连续的 Region，打包给它。

这些连续 Region 的第一块叫 **Start Humongous Region**，后续的叫 **Continues Humongous Region**（名字有时叫 “HC”/“HS” 之类，取决于实现注释）。它们在逻辑上视为一个大对象的“专属地段”。

也就是说：G1 并不会把 Region 动态放大到 2MB，而是会占用多块 1MB 的 Region 作为一个“大拼图”。





**2.3 为什么要连续？**

因为这个大对象本质上还是要看起来像“一段线性内存”，给 Java 程序就是一个 new byte[2*1024*1024] 这样的大数组，JVM 依然需要它是连续地址空间。所以它不能碎片化成离散 Region 再靠 indirection 拼，必须是物理连续的若干 Region。





**2.4 这些 Humongous Region 属于年轻代还是老年代？**

几乎总是直接进老年代（old / tenured 区域的角色）。

原因是：这种巨型对象如果你把它当成 Eden 里的普通临时对象然后频繁拷贝晋升，成本和失败概率都很高。G1 直接把它们放到老年代的语义区域里，避免反复复制。

这也解释了一个面试常问点：

> G1 说是“复制-压缩”的收集器，那大对象会被复制吗？

> 答案是：**Humongous 对象一般不会在 Minor GC 里复制**，它们只在 Full GC 或特殊回收路径里被清理/回收。





**2.5 这有什么代价？**

代价主要有两个：

1. **内存碎片化压力更大：**

   因为 Humongous Object 需要连续的多块 Region，如果堆长期运行后，能拿出 N 块连续 Region 变得困难，就可能导致 Humongous allocation failed → 触发更重的 GC（甚至 Full GC）。

2. **回收不够精细：**

   普通对象回收时，G1 可以回收单个 Region（收益评估后按 Region 回收）。

   但 Humongous 对象是跨好几个 Region 的，往往要等整个对象都死了，那几块 Region 才能一口气全回收，否则中间那几块你也不能复用。



如果你还能补一句“这为什么重要”，面试体验会直接好一档：

> 这种设计让 G1 可以按 Region 维度精确统计垃圾比例，然后优先回收“收益最高”的 Region，从而在停顿时间预算内，最大化回收吞吐——这就是 Garbage-First 这个名字的来源。



## 为什么 G1 不把内存区块设计的像jemalloc由多种不同大小的区块去成

好问题！先把“Redis 的多尺寸内存块”和“G1 的 Region”放到同一张桌上对比一下：

Redis（更准确说是它常见的分配器 jemalloc）解决的是**应用内部的内存分配**问题，它不移动对象，靠**多种大小类（size classes）降低碎片；而 G1 解决的是托管堆的垃圾回收**问题，它**会移动对象**，并且整套算法围绕“按 Region 为单位统计/选择/转移/回收”来构建。二者目标与约束不一样，因此设计也不一样。

下面是 G1 不做“多种不同大小 Region”的核心原因（也是它坚持固定大小 Region 的价值）：



1. **停顿时间可预测性（Pause Budgeting）**

   G1 的关键卖点是“在目标停顿时间内，选一批回收收益最高的 Region（Collection Set）”。

- 代价模型近似为：回收时间 ≈ Σ(扫描RSet成本 + 存活字节搬迁成本)，这些成本在**固定大小**的 Region 上可线性估计且波动小。
- 如果 Region 大小各不相同，单个 Region 的回收时间方差变大，CSet 选取会变得难以拟合目标停顿，从而降低预测准确性。



2. **Remembered Set（RSet）与 Card Table 的简单高效映射**

- G1 用 **Card Table（按固定卡粒度）+ RSet（跨区引用的反向指针集）** 来追踪跨 Region 引用。
- 固定大小 Region 能把“地址→RegionId”的计算简化为移位/掩码，RSet 的数据结构也能做成**按 Region 索引的稀疏/密集表**。
- 一旦 Region 大小不一，RSet 的索引和空间布局都会复杂很多，维护与查询成本上升。



3. **并行/并发阶段的负载均衡**

- GC 工作线程按 Region 粒度分工、工作窃取。**同尺寸**粒度能显著减少“长尾 Region”拖慢一组工作线程的概率。
- 多尺寸 Region 会导致单位任务粒度差异大，容易出现某个线程卡在“大块 Region”上，整体尾延迟上升。



4. **垃圾优先（Garbage-First）收益排序的可比性**

- G1 以“每个 Region 的存活率 / 垃圾量 / RSet 代价”做**收益评估**并排序。
- 统一大小使得“收益/单位停顿”的比较更公平稳定；如果大小不同，你需要复杂的归一化，且误差更大。



5. **碎片治理策略不同：G1 靠“搬家+整块回收”，不靠“尺寸分类”**

- jemalloc 的多尺寸是为了**不移动对象**前提下控制外部碎片；
- G1 会在回收时把**活对象复制出该 Region**，然后整块释放整个 Region——这天生就把外部碎片问题极大缓解了（空闲以**整 Region**计）。
- 如果再引入多种 Region 尺寸，反而会重新引入“需要找一段合适大小且尽量连续的空闲块”的复杂度。



6. **实现复杂度 vs. 实际收益**

- “多尺寸 Region”理论上能减少 Humongous 对象（≥ 0.5×Region）的比例，但与此同时会大幅增复杂度：RSet 组织、代价模型、调度、负载均衡、可视化与调优都更难。
- 现实里 Humongous 对象在大多数业务占比并不高；对这类场景，**调大 Region 大小**即可权衡（-XX:G1HeapRegionSize），不必改架构基本盘。

顺带补充两个容易混淆的点：

- **G1 也用“多种大小”的缓冲，但在 Region 之内**：线程本地分配区 TLAB、GC 复制用的 PLAB 会自适应大小，它们不改变 Region 大小，只是**在 Region 内部**切出不同长度的连续小段，提高分配与复制效率。
- **Humongous 对象**（大小 ≥ 0.5×RegionSize）并不是通过“变大 Region”解决，而是**占用多块连续 Region**。如果你的业务常有 2–8MB 的大数组/ByteBuffer，可以考虑把 Region 调到 2–8MB 区间，降低 Humongous 频率，但代价是：Region 变大 → 回收粒度变粗，混合回收的“可挑选性”下降，停顿时间调度更粗糙，需要结合压测权衡。

**一句话总结**：

Redis/jemalloc 的多尺寸块是“**不移动对象**条件下的碎片管理术”；G1 的设计哲学是“**移动对象、固定尺寸 Region、整块回收**”，用统一粒度来换取**停顿可预测、RSet 简洁、并行负载均衡和收益排序的稳定性**。两者面对的是不同问题集，因而采用了不同的最优解。





## 卡表和 Rset

下面把两件事讲清楚：**卡表（Card Table）是什么**、**Remembered Set（RemSet/RSet）是什么**，以及它们在 G1/并代收集器中的关系、维护方式与使用时机。





### **1. 卡表（Card Table）**

**定义**：把整个 Java 堆按固定粒度切成很多“小卡片（card）”，HotSpot 常见粒度是 **512B** 一卡。为每张卡维护一个状态字节（clean/dirty 等）。

**作用**：在写屏障（write barrier）的配合下，标记“**哪些内存区域可能包含了** 指向某个目标集合（比如年轻代）的**新引用**”，从而在 GC 时**只扫描被标脏的卡片**，避免全堆扫描。

**维护（post-write 屏障）的大致逻辑**（伪码）：

```
on_reference_store(p, new_ref):
  card = card_of(address(p))
  if card.is_clean():
     card.mark_dirty()
     // G1 会把这张卡地址塞进线程本地的 DirtyCardQueue（见 §3）
```

> 直观理解：**卡表是“谁可能变脏了”的地毯图**，由 post-write 屏障把地毯某格染色，GC 时只掀起被染色的格子看看里面有没有跨区/跨代指针。

在 **Parallel/Serial/CMS** 等**代际收集**里，卡表最经典用途是 **Old→Young 的脏卡集合**（Minor GC 扫这些卡，找到老年代里指向新生代的引用）。





### **2. RSet（Remembered Set）**

**定义（G1 语义）**：对**每一个 Region**，记录“**哪些别的 Region 的哪些卡**里，存在**指向本 Region 的引用**”。也就是**“入边索引”**：从外部指向我这一块的引用在哪里。



**作用**：G1 的 Young/Mixed GC 会挑出一批要回收的 Region（CSet）。扫描根与存活对象时，只需**扫描这些 Region 的 RSet**——即**只看“别人指向我”的来源集合**，无需扫描整个老年代或整个堆。



**与卡表的关系**：

- **卡表是全堆一张的“脏位图”**（按 512B 维护），**不分目标**；
- **RSet 是“按目标 Region 分桶”的索引**，把“某张脏卡”**归档到它所指向的目标 Region 的 RSet**中。
- 因此在 G1 中：**卡表是原始信号，RSet 是按 Region 聚合后的可用索引**。





### **3. G1 中 RSet 的维护流水线**

**关键玩家**：post-write 屏障、Dirty Card Queue（DCQ）、并发 Refinement 线程、RSet 内部结构。

1. **程序写引用 → post-write 屏障**

   - 把对应卡标记为 dirty；
   - 把**卡地址**压入**线程本地 DCQ**（DirtyCardQueue）。

   

2. **并发 Refinement**（后台线程批处理 DCQ）

   - 从队列取出一张“脏卡”，**扫描这张卡覆盖的 512B 内存**，找出里面的每个引用 r；
   - 若 r 指向 **目标 Region = T**，则把“**来源 Region 的这张卡**”加入 **T 的 RSet**。
   - 这一步把“原始脏卡信号”转成“按目标 Region 组织的索引”。

   

3. **背压与协助**

   - DCQ 太长时，**应用线程可能被要求协助做一部分 refinement**（mutator assist），以把维护工作摊在并发期完成，减少 GC 停顿内的负担。

   

4. **RSet 的内部形态（精粗并存）**

   - **Sparse/细粒度表**：当某目标 Region 的入边很少时，用**稀疏哈希**记录“来源 Region 的少量卡片索引”；
   - **Fine/PRT（Per-Region Table）**：来源多起来后转成**来源 Region × 卡索引**的更紧凑表；
   - **Coarse**：极端情况下退化为“**整来源 Region 作为一条粗粒度项**”（等价于说“来源 Region 里**任何卡**都可能指向目标”）。
   - 这种**多形态自适应**兼顾空间与更新时间，但**coarse** 会在 GC 扫描时放大工作量（更多“怀疑”需要扫描）。

```
(运行中)
mutator write  ──► CardTable 标脏 ──► DirtyCardQueue
                                  │
                                  ▼
                     Refinement 扫卡并“归档”
                                  │
                                  ▼
                     RSet[T] ← 记录“谁指向 Region T”

(STW: Young/Mixed GC)
起点 = GC Roots  ∪  (⋃  R∈CSet  RSet[R])
      │
      └─► 只从这些来源追踪到 CSet 内对象 → 复制/晋升
           未触达的对象死 → 整块释放 Region
```



### **4. G1/Parallel 在使用阶段的差异**

- **Parallel（PS Young）**：Minor GC 时**直接用卡表的 Old→Young 脏卡集合**做来源扫描；Full/Old 收集则多为全量并行扫描。**没有 per-region RSet** 的概念。
- **G1**：Young/Mixed GC 时**只扫描 CSet 中每个 Region 的 RSet**（“谁指向我”），**不必**遍历整个老年代；并且它的**并发标记**采用 SATB（pre-write 屏障记录旧值），与 RSet/卡表的 post-write 屏障**并行存在、各司其职**。

- **卡表 = 变更捕获机制**（谁被写过）→ **G1 和 Parallel 都有**；

- **RSet = 按目标 Region 建的入边索引**（谁指向我）→ **主要是 G1 的东西**；

- **G1 同时用两者**：卡表负责采集，RSet负责在**GC 时快速、精确地只扫与 CSet 相关的来源**。

- **GC Roots** ⊕ **CSet 中每个 Region 的 RSet**（“谁指向这块”的入边索引）。

- 这样做的效果：

  - **只关注指向 CSet 的跨区引用**，**不**去扫与本次不相关的老年代大部分区域；

  



### **5. 为什么需要两者都存在？**

- **卡表**是**低成本、全堆统一、按写时触发**的“变更日志”；
- **RSet**则是**面向 Region 的查询索引**，让 G1 能在**小停顿预算**内只摸到与 CSet 有关的跨区引用。
- 用类数据库的比喻：**卡表像一张 append-only 的变更流水表**，**RSet 是按“目标分区”建好的二级索引**，GC 时直接走索引查“谁指向这块”。



### **6. 典型开销与调优要点（知其然也知其所以然）**

- **开销来源**：

  1. 写屏障常量开销（每次引用写入）；
  2. DCQ 扫卡与对象头解析（Refinement）；
  3. RSet 空间与结构维护（细→粗形态转换、去重）。

  

- **常见后果**：

  - Refinement 跑不及 → GC 停顿阶段需要“补账”，停顿变长；
  - RSet 过粗 → Mixed/Young GC 扫描量膨胀；
  - Humongous/高引用交叉/热点修改对象 → RSet 更新压力上升。

  

- **思路**：

  - **降低无谓的跨 Region/跨代写**（对象分配/局部化、减少大对象在老年代之间互指）；
  - 让并发 Refinement 有足够 CPU（避免所有活干都挤进停顿里）；
  - 若业务大量大对象且引用稠密，评估 **Region 大小（-XX:G1HeapRegionSize）** 与堆布局，避免 RSet 过度膨胀。



### **7. 小结（面试版 3 句话）**

1. **卡表**：把堆按固定小块分片，写引用时把对应卡标脏，GC 时只扫描脏卡，避免全堆扫。
2. **RSet（G1）**：对每个 Region，记录“**别的 Region 的哪些卡**指向我”，GC 时只扫 CSet 里 Region 的 RSet，做到**精确来源收敛**。
3. **关联**：G1 先用卡表捕捉“变更”，再由并发 refinement 把脏卡**归档入各目标 Region 的 RSet**；两者配合，支撑 G1 的**小停顿、按收益回收**。





好的，我们把两件事拆开讲：**bump-the-pointer（指针碰撞式分配）**是什么、为什么快；以及**TLAB（Thread-Local Allocation Buffer）**如何把它变成“无锁的每线程极速分配”。





## **bump-the-pointer 分配**

### **核心思想**

把一段连续空闲内存当作“水泥地”，维护两个指针：

- top：已用的末尾
- end：可用的末尾



新建对象只要做两步：

1. 计算本对象所需的对齐大小 sz（含对象头、对齐到 8/16 字节）。

2. 检查 top + sz <= end，若足够：

   - obj = top
   - top += sz
   - 在 obj 处写入对象头/klass指针/数组长度等，必要时清零对象体。

   

这就是“**碰一下指针就完成分配**”。没有空闲链表、没有复杂搜索，时间近似 O(1)，而且**内存连续、cache 友好**，JIT 可以把这段逻辑**内联**到调用点。

> HotSpot 在新生代（Eden）大量使用 pointer bumping；老年代复制/晋升阶段也会用类似思想（PLAB，见下文“旁注”）。



### **线程安全问题**

若**多个线程**去“碰同一根指针”，就需要加锁或 CAS 竞争，这会把优势吃掉。因此 HotSpot 的优化是：**不给所有线程共享一个 bump 指针，而是给每个线程分一小块私有的“可 bump 区域”**——这就是 **TLAB**。





## **TLAB（Thread-Local Allocation Buffer）**

- 从 Eden（或对应代的可分配区）里**切一小段连续区域**给某个线程，称为**TLAB**。
- 线程在自己的 TLAB 里**独享 bump-the-pointer**，因此分配**无锁**、无竞争，基本只是一串加法/比较/少量写。





### **分配快路径（JIT 内联后的伪码）**

```
// 线程局部：tlab.top, tlab.end
if (tlab.top + size <= tlab.end) {
    obj = tlab.top;
    tlab.top += size;        // bump
    // 写对象头：mark word、klass 指针、数组长度……
    // 如果需要，清零对象体（见下“清零策略”）
    return obj;
}
// 否则走慢路径（refill 或共享区/老年代分配）
```



### **refill 与慢路径**

当 TLAB 剩余空间装不下下一个对象：

1. **尝试申请一个新的 TLAB**（向共享的 Eden 申请一段新连续区；这一步需要同步/CAS，但不是每次分配都发生，只在**TLAB 用尽时**才发生）。
2. 若对象**特别大**（超过典型 TLAB 目标大小），会**直接在共享 Eden 上分配一块**（仍然是 pointer bumping，但需要一次 CAS）；极端大对象在某些收集器里可能绕过新生代策略（与 Pretenure/大对象策略有关）。
3. 旧 TLAB 剩余的零头会**用填充对象（filler object）**“封口”，保持堆结构可解析（确保对象迭代器能跳过这段空洞）。





### **TLAB 大小如何确定**

- **自适应**：JVM 根据每个线程的**历史分配速率、refill 次数、浪费比例**，动态调整 TLAB 大小，尽量让“快路径命中率”高、又不浪费过多零头。
- 可调开关（不同 JDK 版本略有差异）：
  - -XX:+UseTLAB（默认开启）
  - -XX:+ResizeTLAB（自适应）
  - -XX:MinTLABSize、-XX:TLABWasteTargetPercent 等（影响目标大小/浪费阈值）
- **目标**：把“需要去共享 Eden 申请新 TLAB 的慢路径”频率降到合适水平，同时控制尾部碎片。





### **清零策略（zeroing）**

Java 语义要求新对象字段初始为 0。HotSpot 常见做法：

- **Eden 预清零**（GC 后把 Eden 置零），或
- **按需清零**：在分配时仅清零“新对象区域”；JIT 会尽量消除/矢量化清零循环。
- 对 TLAB，会维护“已清零边界”，确保快路径最多做极少量清零或完全省掉（取决于 GC/平台策略与标志位）。





### **为什么 TLAB 如此有效**

- **无锁**：绝大多数对象分配都发生在各自线程的 TLAB 内，避免热点锁/CAS。
- **线性**：连续写入、顺序访问，cache 命中率高，硬件预取友好。
- **可内联**：JIT 把快路径直接内联，堆栈上就几条指令。



### **和收集器的关系**

- **新生代复制式收集器**（如 G1/Parallel/Serial 的年轻代）：TLAB 是默认搭配。
- **老年代晋升**时，GC 线程也有自己的 **PLAB（Promotion LAB）**，本质同一套路：每个 GC 线程有一块私有“复制目的地缓存”，复制幸存对象时同样 bump-the-pointer，减少竞争。





### **关键边界与细节**

- **超大对象**

  - 若对象大小**超过 TLAB 目标尺寸**，一般**直接走共享 Eden**分配（一次 CAS），而不是为了它扩建一个巨大的 TLAB。
  - 极端大的对象（相对单 Region/分代阈值）在部分收集器上可能采用单独策略（如 G1 的 humongous 路径不走 TLAB）。

  

- **对齐与填充对象**

  - 堆对象通常按 8/16 字节对齐。TLAB 尾部空隙会用**填充对象**填满，保证堆可线性遍历。

  

- **可见性与写屏障**

  - 分配本身不涉及跨区引用；但把对象放到共享结构/写入引用字段时，仍要经过**写屏障**维护卡表/RSet。

  

- **禁用 TLAB**

  - -XX:-UseTLAB 可用于调试/实验。禁用后每次分配都得在共享 Eden 上 CAS bump，**性能通常会明显下降**（高并发更显著）。

  





### **小结（面试 30 秒版）**

- **bump-the-pointer**：在一段连续空闲区用 top/end 两个指针，top += size 即得新对象，O(1)、cache 友好、可内联。
- **TLAB**：为每个线程从 Eden 划一小段“私有可 bump 的缓冲区”，让绝大多数分配**无锁**完成；TLAB 用尽时再去共享 Eden 申请新 TLAB。
- **收益**：把“分配的同步/CAS”摊薄成“偶尔 refill”，提升吞吐与延迟；GC 和晋升阶段也用同样思路（PLAB）降低线程间竞争。