## **1) CPU骤降 + 请求超时/堆积**

- 可能原因：DB/缓存不可达（连接池阻塞、DNS卡顿）、下游限流/半故障、线程池把线程都“卡在 IO 上”。
- 快速确认：
  - top 看 CPU idle 高、vmstat 1 看 wa 高；netstat/ss 看大量 SYN-SENT/TIME_WAIT；
  - 业务线程 dump：jcmd $pid Thread.print 看大量线程阻塞在 JDBC/Redis/KV 的 get/execute；
  - 连接池指标：active≈max、等待队列暴涨；DB/Redis端也看连接数/慢查询。
- 临时止血：调大**超时**（读/写/连接三个），开启**熔断/限流**、**快速失败**；增开实例分流；若是 DNS，切直连或本地 hosts。
- 长期修复：合理**池大小 & timeout**（Hikari：maximumPoolSize、connectionTimeout）、**断路器/重试预算**、**失败隔离**（不同下游分不同线程池）、**本地缓存/降级**；DNS 缓存参数（networkaddress.cache.ttl）。





## **2) CPU拉满 + QPS下降 + p99暴涨，GC正常**

- 可能原因：热点**锁竞争/自旋**、对象创建风暴、正则/JSON 解析热路径、日志同步 IO。
- 确认：perf top/async-profiler 火焰图看热点；jstack 看大量 BLOCKED/parking；应用指标看热点接口。
- 临时：快速**限流**、降日志级别/异步化；把巨型正则换预编译。
- 长期：**减少共享锁/缩小临界区**、换无锁/分段结构；池化/复用对象（注意逃逸分析）；关键路径改用更快的编解码器。





## **3) Full GC/Mixed GC 频繁 + 停顿长 + Old 占用高**

- 可能原因：**内存泄漏/缓存无界**、大对象（G1 Humongous）、RSet 过大导致扫描慢。
- 确认：GC 日志（-Xlog:gc*）、jcmd GC.heap_info、jmap -histo 排前列类；G1 看 humongous 占比、to-space exhausted。
- 临时：**提高堆**或**放宽暂停目标**（MaxGCPauseMillis）、清理缓存、降低并发度。
- 长期：给缓存**上界+淘汰**，拆大对象/分块；G1 调整 G1HeapRegionSize 降低 humongous 频率；排查泄漏（ThreadLocal/Listener/集合未清）。





## **4) CPU低 + LoadAverage高 + iowait 高 + RT 高**

- 可能原因：**磁盘/网络 IO 瓶颈**（慢盘、NFS、云盘抖动）、频繁 fsync、日志落盘阻塞。
- 确认：vmstat 1（wa 高）、iostat -x 1（await、util 高）、sar -n 看网络丢包/重传。
- 临时：把热数据/日志**切到本地盘**，提高缓冲、异步落盘；关闭 debug 日志。
- 长期：存储/网络规格升级；使用**异步 IO/批量**；日志采集异步化、限速。





## **5) 发布后短时间 p99/p999 飙高，随后恢复**

- 可能原因：**JIT 未预热**、**缓存冷启动**、连接池 minSize 太小。
- 确认：只在发布窗口抖；JIT/JFR 事件显示大量编译；缓存 miss 高。
- 临时：**灰度/预热**：放健康检查/影子流量；发布前跑一轮热身脚本。
- 长期：**AOT/klass 预热**（有限支持）、**提升最小连接数**、冷启动旁路缓存/慢路径限流。





## **6) 线程数/请求队列暴涨 + CPU仍不高**

- 可能原因：**线程池过大 + 下游慢** → 大量线程阻塞；或线程泄漏。
- 确认：线程 dump 看大量 RUNNABLE 卡在 read/lock；线程池队列长度、active 数；ulimit -u。
- 临时：**收敛线程池**（宁可排队也别卡死 OS）、**超时/熔断**、隔离关键下游到独立池。
- 长期：**异步化**/反压模型；线程池与连接池**容量匹配**；全链路限流/舱壁。





## **7) OOMKilled / 容器重启 + 短时 5xx**

- 可能原因：容器内存**上限小于 JVM 真实需求**；未开启容器感知；**Direct/Native** 内存涨（Netty/ByteBuffer）、Metaspace 涨。
- 确认：kubectl describe pod 看 OOMKilled；jcmd VM.native_memory summary；/proc/meminfo；GC 日志看 OutOfMemoryError 与否。
- 临时：提高容器 limit，先把 -Xmx 降到安全线；限制 Netty Arena。
- 长期：JDK11+ 确保容器感知；**总内存预算**= heap + metaspace + codecache + direct + TLS + mmap；加 NMT 监控。





## **8) Kafka 消费延迟拉大 + 频繁 rebalance**

- 可能原因：**长 GC/Stop-The-World** 或应用里**阻塞 poll**；心跳超时；批处理过大。
- 确认：Broker/Consumer 日志；JFR/GC 日志对应时间段；消费线程栈在 poll/业务处理。
- 临时：缩短批量/单条处理时间、调大 max.poll.interval.ms；降低并发、减少反压。
- 长期：消费者**线程模型隔离**（poll 与处理分离）、**幂等与重试**、优化 GC 停顿。





## **9) Redis RT 高 + QPS 高 + CPU单核顶满**

- 可能原因：**热键/大 key/大量** **SCAN****/****SORT**；pipeline 不合理；网络 RTT。
- 确认：LATENCY DOCTOR、slowlog、monitor 抓热点命令；对象大小分布。
- 临时：**限流/隔离热点**、拆大 key、禁用线上 KEYS/SCAN；就近部署。
- 长期：**分片**、二级缓存、热点专库/本地缓存；合理 pipeline/批量。





## **10) 请求大量超时但无错误日志**

- 可能原因：**DNS 解析慢/失败**、连接建立被防火墙丢弃、SYN backlog 满。
- 确认：抓包看 DNS RTT；ss -s/netstat -s；resolv.conf 配置；dig 实测。
- 临时：**直连 IP/hosts**、本地 DNS 缓存；调大连接超时但限制重试次数。
- 长期：networkaddress.cache.ttl、内部 DNS 高可用/就近；TCP backlog、rmem/wmem 调优。





## **11) 线上偶发“应用卡死几秒 ~ 十几秒”**

- 可能原因：**长时间 safepoint**（VM Operation：Deoptimize, RevokeBias 等）、jmap/heap dump、Stop-the-world profiling。
- 确认：JFR/GC 日志里 safepoint 事件；运维是否在抓 dump。
- 临时：停止重操作采样；用 **async-profiler** 代替 STW 工具。
- 长期：减少会触发全局 STW 的运维操作；升级 JDK、关闭不需要的偏向锁（JDK8）。





## **12) HTTP 连接数爆炸 + TIME_WAIT/ESTABLISHED 异常**

- 可能原因：**未复用连接**（Keep-Alive 关/代理干掉 KA）、连接池错误配置、服务端 Idle 超时太短。
- 确认：客户端连接池指标（ leased/available/idle）、抓包看是否复用；服务端 server.keepAliveTimeout。
- 临时：开启/拉长 Keep-Alive、增大连接池上限、限制并发新建。
- 长期：**连接复用与上限**按 QPS/RT 计算；对代理/网关统一 KA 策略；HTTP/2 优化复用。





# **快速排障最小闭环（随手表）**

1. **进程/机器态**：top, vmstat 1, iostat -x 1, sar -n TCP,DEV 1

2. **JVM 态**：

   - 线程：jcmd $pid Thread.print（或 jstack）
   - GC：-Xlog:gc*:tags（JDK11+），jstat -gcutil $pid 1s
   - 堆/类元：jcmd $pid GC.heap_info, VM.native_memory summary

   

3. **中间件态**：连接池（活跃/等待）、下游 RT/错误率、Kafka lag、Redis 慢日志

4. **临时止血**：限流/降级/熔断、隔离线程池、拉长超时但**限制重试**、扩副本

5. **复盘与长期修复**：容量/池化/超时/重试预算、缓存上界、GC 与对象模型优化、网络与存储 SLO